<!-- This website was made with the help of ChatGPT -->

<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Zhi Wang's Homepage</title>
  <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/aaaakshat/cm-web-fonts@latest/fonts.css">
  <style>
  body, div {
    font-family: "Computer Modern Serif", serif;
  }
  a {
    color: #105e8a;
  }
  .outer-container {
    margin: 0 21.5%;
  }
  .container {
    width: 100%;
    box-sizing: border-box;
    display: flex;
    align-items: center;
    font-family: "Times New Roman", Times, serif;
  }
  .photo {
    flex: 1;
    max-width: 145px;
  }
  .text {
    flex: 4;
    padding-right: 2%;
  }
  .header {
    background-color: white;
    color: black;
    display: flex;
    margin-top: 20px;
    justify-content: space-between;
    align-items: center;
  }
  .navbar {
    display: flex;
  }
  .navbar a {
    color: black;
    text-decoration: none;
    margin: 0 10px;
  }
  .title {
    margin: 0;
  }
  .scroll-to-top {
    position: fixed;
    bottom: 20px;
    right: 20px;
    background-color: #696969;
    color: white;
    padding: 10px;
    text-decoration: none;
    display: none;
  }
  button {
    background-color: #FFFFFF;
    border: none;
    cursor:pointer;
    color: #105e8a;
    text-decoration: underline;
    font-family: "Times New Roman", Times, serif;
    font-size: 100%;
  }
  blockquote {
    display: block;
    border-left: solid black;
    border-left-width: thin;
    margin-left: 1%;
    padding-left: 2.5%;
  }
  pre {
    overflow-x: scroll;
  }
  ul {
    list-style-type: disc;
    padding-left: 2.5%;
  }
  @media only screen and (min-width: 800px) and (max-width: 1050px) {
    .outer-container {
      margin: 0 13.5%;
    }
  }
  @media only screen and (max-width: 800px) {
    body, div {
      text-align: left;
      font-size: 13.5px;
    }
    h1 {
      font-size: 1.8em;
    }
    ul {
      padding-left: 2.5%;
    }
    blockquote {
      margin-left: 5px;
      padding-left: 2.5%;
    }
    .outer-container {
      margin: 0 7.5%;
    }
    .container {
      flex-direction: column;
    }
    .photo {
      flex: none;
      max-width: 25%;
      height: auto;
      display: block;
      margin: 0 auto;
    }
    .text {
      flex: none;
      width: 100%;
    }
    .navbar {
      display: none;
    }
    .title {
      padding-left: 0;
      text-align: center;
      flex-grow: 1;
      text-align: center;
    }
  }
  p.small {
    font-variant: small-caps;
  }
</style>
</head>

<body>
<div class="outer-container">

  <div id="header" class="header">
    <h1 class="title">Zhi Wang</h1>
    <div class="navbar">
        <a href="#research"><b>Research</b></a>
        <a href="#teaching"><b>Teaching</b></a>
        <a href="#service"><b>Service</b></a>
        <a href="#contact"><b>Contact</b></a>
    </div>
  </div>

  <div class="container">
    <div class="text">
      <p>I am a postdoctoral research associate at the University of Wisconsin-Madison, working with <a href="https://ramyakv.github.io">Ramya Korlakai Vinayak</a>. 
        <!-- <span style="color: red;">I am on the job market. Please <a href="mailto:zhiwang@ucsd.edu" style="color: #800080;">let me know</a> if you have any leads!</span> --> 
      </p>

      <p>My main research interests are in machine learning, with a focus on problems that involve heterogeneity, adaptability, or both. This includes studying how models learn and generalize across diverse tasks, potentially over time, within non-traditional paradigms such as interactive learning and sequential decision-making.</p>      

      <p>I received my Ph.D. in Computer Science from the University of California San Diego (UCSD), where I was advised by <a href="http://cseweb.ucsd.edu/~kamalika/">Kamalika Chaudhuri</a>. 
        Before joining UCSD, I obtained my B.S. in Computer Science from the University of Southern California, where I worked with <a href="https://tkskwork.org">T. K. Satish Kumar</a> and <a href="http://idm-lab.org">Sven Koenig</a> on combinatorial search, planning and scheduling, and constraint satisfaction, among others.</p>
    </div>
    <img class="photo" src="photo.jpg" alt="photo">
  </div>

  <hr>

  <div id="research">
  <!-- <h3>Preprints</h3> -->
  <!-- <hr> -->

  <!-- <h3>Manuscripts</h3> -->
  <!-- <hr> -->

  <h3>Selected Publications</h3>
  <ul>
  <li>
    Daiwei Chen, Yi Chen, Aniket Rege, <b>Zhi Wang</b>, Ramya Korlakai Vinayak.
    <b>PAL: Sample-Efficient Personalized Reward Modeling for Pluralistic Alignment</b>. <i>The 13th International Conference on Learning Representations</i> (ICLR-2025).
    <br>
    <button onclick="displayText('pal_abstract')">[abstract]</button>
    <a href="https://openreview.net/forum?id=1kFDrYCuSu">[OpenReview]</a><br>
    <blockquote id="pal_abstract" style = "display:none" >
    Foundation models trained on internet-scale data benefit from extensive alignment to human preferences before deployment. However, existing methods typically assume a homogeneous preference shared by all individuals, overlooking the diversity inherent in human values. In this work, we propose a general reward modeling framework for pluralistic alignment (PAL), which incorporates diverse preferences from the ground up. PAL has a modular design that leverages commonalities across users while catering to individual personalization, enabling efficient few-shot localization of preferences for new users. Extensive empirical evaluation demonstrates that PAL matches or outperforms state-of-the-art methods on both text-to-text and text-to-image tasks: on Reddit TL;DR Summary, PAL is 1.7% more accurate for seen users and 36% more accurate for unseen users compared to the previous best method, with 100× less parameters. On Pick-a-Pic v2, PAL is 2.5% more accurate than the best method with 156× fewer learned parameters. Finally, we provide theoretical analysis for generalization of rewards learned via PAL framework showcasing the reduction in number of samples needed per user.    </blockquote>
  </li>
  </ul>
  <ul>
  <li>
    Thang Duong, <b>Zhi Wang</b>, Chicheng Zhang.
    <b>Beyond Task Diversity: Provable Representation Transfer for Sequential Multitask Linear Bandits</b>. <i>Advances in Neural Information Processing Systems 37</i> (NeurIPS-2024).
    <br>
    <button onclick="displayText('beyond_task_diversity_abstract')">[abstract]</button>
    <a href="https://arxiv.org/abs/2501.13390">[arXiv]</a><br>
    <blockquote id="beyond_task_diversity_abstract" style = "display:none" >
    We study lifelong learning in linear bandits, where a learner interacts with a sequence of linear bandit tasks whose parameters lie in an \( m \)-dimensional subspace of \( \mathbb{R}^d \), thereby sharing a low-rank representation. Current literature typically assumes that the tasks are <i>diverse</i>, i.e., their parameters uniformly span the \( m \)-dimensional subspace. This assumption allows the low-rank representation to be learned before all tasks are revealed, which can be unrealistic in real-world applications. In this work, we present the first nontrivial result for sequential multi-task linear bandits without the task diversity assumption. We develop an algorithm that efficiently learns and transfers low-rank representations. When facing \( N \) tasks, each played over \( \tau \) rounds, our algorithm achieves a regret guarantee of \( \tilde{O} (Nm \sqrt{\tau} + N^{\frac{2}{3}} \tau^{\frac{2}{3}} d m^{\frac13} + Nd^2 + \tau m d ) \) under the ellipsoid action set assumption. This result can significantly improve upon the baseline of \( \tilde{O}  (Nd \sqrt{\tau} ) \) that does not leverage the low-rank structure when the number of tasks \( N \) is sufficiently large and \( m \ll d \). We also demonstrate empirically on synthetic data that our algorithm outperforms baseline algorithms, which rely on the task diversity assumption. 
    </blockquote>
  </li>
  </ul>
  <ul>
  <li>
    <b>Zhi Wang</b>, Geelon So, and Ramya Korlakai Vinayak.
    <b>Metric Learning from Limited Pairwise Preference Comparisons</b>. <i>Proceedings of the 40th Conference on Uncertainty in Artificial Intelligence</i> (UAI-2024).
    <br>
    <button onclick="displayText('metric_learning_abstract')">[abstract]</button>
    <a href="https://arxiv.org/abs/2403.19629">[arXiv]</a><br>
    <blockquote id="metric_learning_abstract" style = "display:none" >
    We study metric learning from preference comparisons under the ideal point model, in which a user prefers an item over another if it is closer to their latent ideal item. These items are embedded into \( \mathbb{R}^d \) equipped with an unknown Mahalanobis distance shared across users. While recent work shows that it is possible to simultaneously recover the metric and ideal items given \( O(d) \) pairwise comparisons per user, in practice we often have a limited budget of \( o(d) \) comparisons. We study whether the metric can still be recovered, even though it is known that learning individual ideal items is now no longer possible. We show that in general, \( o(d) \) comparisons reveals no information about the metric, even with infinitely many users. However, when comparisons are made over items that exhibit low-dimensional structure, each user can contribute to learning the metric restricted to a low-dimensional subspace so that the metric can be jointly identified. We present a divide-and-conquer approach that achieves this, and provide theoretical recovery guarantees and empirical validation.
    </blockquote>
  </li>
  </ul>
  <ul>
  <li>
    <b>Zhi Wang</b>, Chicheng Zhang, and Kamalika Chaudhuri.
    <b>Thompson Sampling for Robust Transfer in Multi-Task Bandits</b>. <i>Proceedings of the 39th International Conference on Machine Learning</i> (ICML-2022). <br>
    <button onclick="displayText('multitask_ts_abstract')">[abstract]</button>
    <a href="https://arxiv.org/abs/2206.08556">[arXiv]</a><br>
    <blockquote id="multitask_ts_abstract" style = "display:none" >
    We study the problem of online multi-task learning where the tasks are performed within similar but not necessarily identical multi-armed bandit environments. In particular, we study how a learner can improve its overall performance across multiple related tasks through robust transfer of knowledge. While an upper confidence bound (UCB)-based algorithm has recently been shown to achieve nearly-optimal performance guarantees in a setting where all tasks are solved concurrently, it remains unclear whether Thompson sampling (TS) algorithms, which have superior empirical performance in general, share similar theoretical properties. In this work, we present a TS-type algorithm for a more general online multi-task learning protocol, which extends the concurrent setting. We provide its frequentist analysis and prove that it is also nearly-optimal using a novel concentration inequality for multi-task data aggregation at random stopping times. Finally, we evaluate the algorithm on synthetic data and show that the TS-type algorithm enjoys superior empirical performance in comparison with the UCB-based algorithm and a baseline algorithm that performs TS for each individual task without transfer.
    </blockquote>
  </li><br>
  <li>
      Chicheng Zhang, <b>Zhi Wang</b>.
      <b>Provably Efficient Multi-Task Reinforcement Learning with Model Transfer</b>. <i>Advances in Neural Information Processing Systems 34</i> (NeurIPS-2021). 
      <!-- A shorter version of this work appeared in the Workshop on Reinforcement Learning Theory at ICML-2021. -->
      <br>
    <button onclick="displayText('neurips21_abstract')">[abstract]</button>
      <a href="https://arxiv.org/abs/2107.08622">[arXiv]</a><br>
      <blockquote id="neurips21_abstract" style = "display:none" >
    We study multi-task reinforcement learning (RL) in tabular episodic Markov decision processes (MDPs). We formulate a heterogeneous multi-player RL problem, in which a group of players concurrently face similar but not necessarily identical MDPs, with a goal of improving their collective performance through inter-player information sharing. We design and analyze an algorithm based on the idea of model transfer, and provide gap-dependent and gap-independent upper and lower bounds that characterize the intrinsic complexity of the problem.
      </blockquote>
  </li><br>
  <li>
      <b>Zhi Wang&#42</b>, Chicheng Zhang&#42, Manish Kumar Singh, Laurel D. Riek, and Kamalika Chaudhuri.
      <b>Multitask Bandit Learning through Heterogeneous Feedback Aggregation</b>. <i>Proceedings of the 24th International Conference on Artificial Intelligence and Statistics</i> (AISTATS-2021). 
      <!-- A preliminary version of this work appeared in the Workshop on Real World Experiment Design and Active Learning at ICML-2020. &#42These authors contributed equally. -->
      <br>
    <button onclick="displayText('aistats21abstract')">[abstract]</button>
    <a href="https://arxiv.org/abs/2010.15390">[arXiv]</a><br>
      <blockquote id="aistats21abstract" style = "display:none" >
      In many real-world applications, multiple agents seek to learn how to perform highly related yet slightly different tasks in an online bandit learning protocol. We formulate this problem as the &epsilon;-multi-player multi-armed bandit problem, in which a set of players concurrently interact with a set of arms, and for each arm, the reward distributions for all players are similar but not necessarily identical. We develop an upper confidence bound-based algorithm, <p class="small" style="display:inline">RobustAgg</p>(&epsilon;), that adaptively aggregates rewards collected by different players. In the setting where an upper bound on the pairwise similarities of reward distributions between players is known, we achieve instance-dependent regret guarantees that depend on the amenability of information sharing across players. We complement these upper bounds with nearly matching lower bounds. In the setting where pairwise similarities are unknown, we provide a lower bound, as well as an algorithm that trades off minimax regret guarantees for adaptivity to unknown similarity structure.
      </blockquote>
  </li><br>
  <li>
     <b>Zhi Wang</b>, Liron Cohen, Sven Koenig, and T. K. Satish Kumar. <b>The Factored Shortest Path Problem and Its Applications in Robotics</b>. <i>Proceedings of the 28th International Conference on Automated Planning and Scheduling</i> (ICAPS-2018).<br>
     <button onclick="displayText('icaps18abstract')">[abstract]</button>
     <a href="papers/icaps18.pdf">[pdf]</a>
     <blockquote id="icaps18abstract" style = "display:none" >
     Many real-world combinatorial problems exhibit structure in the way in which their variables interact. Such structure can be exploited in the form of "factors" for representational as well as computational benefits. Factored representations are extensively used in probabilistic reasoning, constraint satisfaction, planning, and decision theory. In this paper, we formulate the <i>factored shortest path problem</i> (FSPP) on a collection of constraints interpreted as factors of a highdimensional map.We show that the FSPP is not only a generalization of the regular shortest path problem but also particularly relevant to robotics.We develop factored-space heuristics for A* and prove that they are admissible and consistent. We provide experimental results on both random and handcrafted instances as well as on an example robotics domain to show that A* with factored-space heuristics outperforms A* with the Manhattan Distance heuristic in many cases.
     </blockquote>
  </li><br>
  <li>
     T. K. Satish Kumar, <b>Zhi Wang</b>, Anoop Kumar, Craig Milo Rogers, and Craig A. Knoblock. <b>Load Scheduling of Simple Temporal Networks Under Dynamic Resource Pricing</b>. <i>Proceedings of the 32nd AAAI Conference on Artificial Intelligence</i> (AAAI-2018).<br>
     <button onclick="displayText('aaai18abstract')">[abstract]</button>
     <a href="papers/aaai18.pdf">[pdf]</a>
     <blockquote id="aaai18abstract" style = "display:none">
     We study load scheduling of simple temporal networks (STNs) under dynamic pricing of resources. We are given a set of processes and a set of simple temporal constraints between their execution times, i.e., an STN. Each process uses a certain amount of resource for execution. The unit price of the resource is a function of time, \( f(t) \). The goal is to find a schedule of a given STN that trades off makespan minimization against cost minimization within a user-specified suboptimality bound. We provide a polynomial-time algorithm for solving the load scheduling problem when \( f(t) \) is piecewise constant. This has important applications in many real-world domains including the smart home and smart grid domains. We then study the dependency of the unit price of the resource on time as well as the total demand at that time. This leads to a further characterization of tractable, NP-hard, and conjectured tractable cases.
     </blockquote>
  </li><br>
  <li>
     T. K. Satish Kumar, <b>Zhi Wang</b>, Anoop Kumar, Craig Milo Rogers, and Craig A. Knoblock. <b>On the Linear Programming Duals of Temporal Reasoning Problems</b>. The 15th International Symposium on Artificial Intelligence and Mathematics (ISAIM-2018).<br>
     <button onclick="displayText('isaim18abstract')">[abstract]</button>
     <a href="papers/isaim18.pdf">[pdf]</a>
     <blockquote id="isaim18abstract" style = "display:none">
     Temporal reasoning problems occur in many application domains of Artificial Intelligence; therefore, it is important for us to develop algorithms for solving them efficiently. While some problems like Simple Temporal Problems are known to be tractable, some other problems like Disjunctive Temporal Problems are known to be NP-hard. In this paper, we provide a Linear Programming (LP) <i>duality</i> perspective on temporal reasoning problems. In many cases, we show that their LP duals are the commonly-studied <i>flow</i> problems in Graph Theory. Using the general theory of LP duality, we develop novel algorithms for efficiently solving several temporal reasoning problems. We also show that other previously-known efficient methods in temporal reasoning also fit into this perspective of LP duality.
     </blockquote>
  </li>
  </ul>
  </div> 

  <hr>

  <div id="teaching">
  <h3>Teaching</h3>
  <ul>
  <li>Instructor, ECE/CS/ME 539: Introduction to Artificial Neural Networks, UW-Madison [<a href="https://canvas.wisc.edu/courses/454920">Summer 2025</a>, Fall 2025] </li> 
  </ul>

  <!-- I was a teaching assistant for the following classes at UCSD:<br>
  <ul>
  <li>DSE 210, Statistics and Probability [Winter 2024]</li> 
  <li>CSE 151A, Introduction to Machine Learning [Winter 2023, Summer 2023, Fall 2023]</li>
  <li>CSE 251A, Principles of Machine Learning: Learning Algorithms [Winter 2021, Winter 2022]</li>
  <li>CSE 291, Topics in Search and Optimization [Winter 2020]</li>
  </ul> -->
  </div>

  <hr>

  <div id="service">
  <h3>Professional Service</h3>
  <ul>
  <li>Conference reviewer: AISTATS (2021-23, 2025), ICML (2022-25), NeurIPS (2021-22, 2024-25), ICLR (2025), COLT (2025)</li>
  <li>Journal reviewer: TMLR (2024-25)</li>
  </ul>
  </div>
  <hr>

  <div id="contact">
  <h3>Contact</h3>
  <p>Office: ECB M1002<br>
  Email: zhi [dot] wang [at] wisc [dot] edu<br>
  <a href="https://scholar.google.com/citations?user=6WLJjCIAAAAJ&hl=en">Google Scholar</a>
  <!-- <a href="https://dblp.uni-trier.de/pers/hd/w/Wang_0013:Zhi">dblp</a></p> -->
  </div>

</div>

<a href="#" class="scroll-to-top">Back to Top</a>

<script>
  window.onscroll = function () {
    var scrollPos = document.documentElement.scrollTop || document.body.scrollTop;
    var scrollToTopBtn = document.querySelector('.scroll-to-top');

    if (scrollPos > 300) {
      scrollToTopBtn.style.display = 'block';
    } else {
      scrollToTopBtn.style.display = 'none';
    }
  };
</script>

<script>
function displayText(id) {
    var x = document.getElementById(id);
    if (x.style.display === "none") {
        x.style.display = "block";
    } else {
        x.style.display = "none";
    }
}
</script>

</body>
</html>
